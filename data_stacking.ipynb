{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8f562c0",
   "metadata": {},
   "source": [
    "Referance\n",
    "- 数据处理[https://blog.csdn.net/erinapple/article/details/81174918]\n",
    "- stacking[https://blog.csdn.net/song430/article/details/90232554]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2568e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#常用工具库\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "#算法辅助 & 数据\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, precision_score, f1_score, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#算法（单一学习器）\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNNC\n",
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.linear_model import LogisticRegression as LogiR\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cgb\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "#融合模型\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "for package in [lgb,cgb,sklearn,mlp,np,pd,xgb]:\n",
    "    print(re.findall(\"([^']*)\",str(package))[2],package.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb958dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "features = [\"user_id\",\"cid\",\"device_type\",\"fix_month\",\"gender\",\"current_role\",\"last_lat\",\"last_lon\",\"hometown\",\"profession\",\"source_channel\",\"work_city_id\",\"home_city_id\",\"work_lon\",\"home_lat\",\"work_lat\",\"home_lon\",\"age_section\",\"age\",\"version\",\"model\",\"label\"]\n",
    "# print(len(features))\n",
    "# print(features)\n",
    "label_file = \"data/0403_churn_2.csv\"\n",
    "\n",
    "# with codecs.open(label_file) as f:\n",
    "#     for line in f.readlines():\n",
    "#         data = line.strip().split(\"\\t\")\n",
    "#         print(data)\n",
    "#         break\n",
    "\n",
    "# create a DataFrame from the dictionary\n",
    "data = pd.read_csv(label_file, delimiter=\"\\t\", names=features).drop(\"cid\", axis=1)\n",
    "\n",
    "# set the column data types\n",
    "dtype = {\n",
    "    'user_id': 'int64',\n",
    "    'device_type': 'int8',\n",
    "    'fix_month': 'int8',\n",
    "    'gender': 'int8',\n",
    "    'current_role': 'int8',\n",
    "    'last_lat': 'float32',\n",
    "    'last_lon': 'float32',\n",
    "    'hometown': 'category',\n",
    "    'profession': 'category',\n",
    "    'source_channel': 'category',\n",
    "    'work_city_id': 'int8',\n",
    "    'home_city_id': 'int8',\n",
    "    'work_lon': 'float32',\n",
    "    'home_lat': 'float32',\n",
    "    'work_lat': 'float32',\n",
    "    'home_lon': 'float32',\n",
    "    'age_section': 'category',\n",
    "    'age': 'int8',\n",
    "    'version': 'category',\n",
    "    'model': 'category',\n",
    "    'label': 'int8'\n",
    "}\n",
    "\n",
    "# apply the column data types to the DataFrame\n",
    "df = data.astype(dtype)\n",
    "print(df.dtypes)\n",
    "\n",
    "df = df.drop(['hometown'], axis=1)\n",
    "\n",
    "# selected_rows_0 = df[df['label'] == 0]\n",
    "# print(len(selected_rows_0))\n",
    "\n",
    "# selected_rows_1 = df[df['label'] == 1]\n",
    "# print(len(selected_rows_1))\n",
    "# df[['user_id','device_type','gender','current_role','source_channel']].head(5)\n",
    "# df[['user_id','profession','work_city_id','work_lon','work_lat']].sample(5)\n",
    "# df[['user_id','hometown','home_city_id','home_lat','home_lon']].sample(5)\n",
    "# df[['user_id','fix_month','version','model']].sample(5)\n",
    "# df[['user_id','work_city_id','home_city_id']].sample(5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46313f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# display the sizes of the two subsets\n",
    "print(\"Training set size: \", len(train_df))\n",
    "print(\"Test set size: \", len(test_df))\n",
    "\n",
    "train_df.head(2)\n",
    "\n",
    "X_train = train_df.drop(['user_id', 'label'], axis=1)\n",
    "y_train = train_df['label']\n",
    "\n",
    "X_train.head(2)\n",
    "\n",
    "X_test = test_df.drop(['user_id', 'label'], axis=1)\n",
    "y_test = test_df['label']\n",
    "\n",
    "\n",
    "# specify the categorical and numerical columns\n",
    "categorical_cols = ['hometown', 'profession', 'source_channel', 'age_section', 'version', 'model']\n",
    "\n",
    "# use one-hot encoding to encode the categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ], remainder='passthrough')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaaecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessor.fit_transform(pd.concat([X_train,X_test], axis=0))\n",
    "X_train = preprocessor.transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_estimators(estimators):\n",
    "    \"\"\"\n",
    "    对模型融合中每个评估器做交叉验证，对单一评估器的表现进行评估\n",
    "    \"\"\"\n",
    "    print(\"---individual_estimators-----\")\n",
    "    proba_train = pd.DataFrame()\n",
    "    proba_test = pd.DataFrame()\n",
    "    scoring = {'auc': 'roc_auc'}\n",
    "    for estimator in estimators:\n",
    "        es_name = estimator[0]\n",
    "        tic = time.time()\n",
    "        cv = KFold(n_splits=5,shuffle=True,random_state=1412)\n",
    "        cv_results = cross_validate(estimator[1],X_train, y_train\n",
    "                             ,cv = cv\n",
    "                             ,scoring = scoring\n",
    "                             ,n_jobs = -1\n",
    "                             ,return_train_score = True\n",
    "                             ,verbose=False)\n",
    "\n",
    "        # print the AUC scores for each fold\n",
    "        print('Mean Time cost {}s'.format(time.time() - tic))\n",
    "        print(cv_results[f'test_auc'])\n",
    "\n",
    "        # calculate the mean AUC score across all folds\n",
    "        mean_auc = cv_results['test_auc'].mean()\n",
    "        model = estimator[1].fit(X_train,y_train)\n",
    "        \n",
    "        # train_proba = model.predict_proba(X_train)[:, 1]\n",
    "        train_proba = model.predict_proba(X_train)[:, 1]\n",
    "        test_proba = model.predict_proba(X_test)[:, 1]\n",
    "        print('Test Time cost {}s'.format(time.time() - tic))\n",
    "        \n",
    "        # calculate the AUC score on the test set\n",
    "        train_auc = roc_auc_score(y_train, train_proba)\n",
    "        test_auc = roc_auc_score(y_test, test_proba)\n",
    "\n",
    "        print(estimator[0]\n",
    "          ,\"\\n Mean AUC:{}\".format(mean_auc)\n",
    "          ,\"\\n train AUC:{}\".format(train_auc)\n",
    "          ,\"\\n test AUC:{}\".format(test_auc)\n",
    "          ,\"\\n\")\n",
    "        \n",
    "        proba_train[es_name] = train_proba\n",
    "        proba_test[es_name] = test_proba\n",
    "        \n",
    "    return proba_train, proba_test\n",
    "print('---new---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe95723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_estimators_precision(estimators):\n",
    "    \"\"\"\n",
    "    对模型融合中每个评估器做交叉验证，对单一评估器的表现进行评估\n",
    "    \"\"\"\n",
    "    print(\"---individual_estimators -----\")\n",
    "    proba_train = pd.DataFrame()\n",
    "    proba_test = pd.DataFrame()\n",
    "    # Set the available scoring metrics\n",
    "    scoring = 'precision'\n",
    "\n",
    "    # Train a final model on the entire dataset using the same cross-validation object\n",
    "    final_model_scores = []\n",
    "    cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1412)\n",
    "    for estimator in estimators:\n",
    "        es_name = estimator[0]\n",
    "        tic = time.time()\n",
    "        cv_results = cross_validate(estimator[1],X_train, y_train\n",
    "                             ,cv = cv\n",
    "                             ,scoring = scoring\n",
    "                             ,n_jobs = -1\n",
    "                             ,return_train_score = True\n",
    "                             ,verbose=False)\n",
    "\n",
    "        #dict_keys(['fit_time', 'score_time', 'test_score', 'train_score'])\n",
    "\n",
    "        # print the AUC scores for each fold\n",
    "        print('Mean Time cost {}s'.format(time.time() - tic))\n",
    "        print(cv_results.keys())\n",
    "        print(cv_results['test_score'])\n",
    "\n",
    "        # calculate the mean AUC score across all folds\n",
    "        mean_es = cv_results[f'test_score'].mean()\n",
    "        model = estimator[1].fit(X_train,y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        print('Test Time cost {}s'.format(time.time() - tic))\n",
    "        # calculate the AUC score on the test set\n",
    "        # train_auc = roc_auc_score(y_train, train_proba)\n",
    "        test_precision = precision_score(y_test, y_pred, average='macro')\n",
    "        # print(\"test AUC:\", test_auc)\n",
    "        print(estimator[0]\n",
    "          ,\"\\n Mean AUC:{}\".format(mean_es)\n",
    "          # ,\"\\n train AUC:{}\".format(train_auc)\n",
    "          ,\"\\n test AUC:{}\".format(test_precision)\n",
    "          ,\"\\n\")\n",
    "        \n",
    "    return proba_train, proba_test\n",
    "print('---new---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd45b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1\n",
    "def individual_estimators_f1(estimators):\n",
    "    \"\"\"\n",
    "    对模型融合中每个评估器做交叉验证，对单一评估器的表现进行评估\n",
    "    \"\"\"\n",
    "    print(\"---individual_estimators precision-----\")\n",
    "    f1_train = pd.DataFrame()\n",
    "    f1_test = pd.DataFrame()\n",
    "    # Set the available scoring metrics\n",
    "    scoring = 'f1'\n",
    "\n",
    "    # Train a final model on the entire dataset using the same cross-validation object\n",
    "    cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1412)\n",
    "    for estimator in estimators:\n",
    "        es_name = estimator[0]\n",
    "        tic = time.time()\n",
    "        cv_results = cross_validate(estimator[1],X_train, y_train\n",
    "                             ,cv = cv\n",
    "                             ,scoring = scoring\n",
    "                             ,n_jobs = -1\n",
    "                             ,return_train_score = True\n",
    "                             ,verbose=False)\n",
    "\n",
    "        #dict_keys(['fit_time', 'score_time', 'test_score', 'train_score'])\n",
    "\n",
    "        # print the AUC scores for each fold\n",
    "        print('Mean Time cost {}s'.format(time.time() - tic))\n",
    "        print(cv_results.keys())\n",
    "        print(cv_results['test_score'])\n",
    "\n",
    "        # calculate the mean AUC score across all folds\n",
    "        mean_es = cv_results['test_score'].mean()\n",
    "        model = estimator[1].fit(X_train,y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        print('Test Time cost {}s'.format(time.time() - tic))\n",
    "        # calculate the AUC score on the test set\n",
    "        train_f1_score = f1_score(y_train, y_train_pred, average='macro')\n",
    "        test_f1_score = f1_score(y_test, y_test_pred, average='macro')\n",
    "        # print(\"test AUC:\", test_auc)\n",
    "        print(estimator[0]\n",
    "          ,\"\\n Mean AUC:{}\".format(mean_es)\n",
    "          ,\"\\n train_f1_score:{}\".format(train_f1_score)\n",
    "          ,\"\\n test_f1_score:{}\".format(test_f1_score)\n",
    "          ,\"\\n\")\n",
    "        \n",
    "        f1_train[es_name] = y_train_pred\n",
    "        f1_test[es_name] = y_test_pred\n",
    "        \n",
    "    return f1_train, f1_test\n",
    "print('---new---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2fa378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "def individual_estimators_recall(estimators):\n",
    "    \"\"\"\n",
    "    对模型融合中每个评估器做交叉验证，对单一评估器的表现进行评估\n",
    "    \"\"\"\n",
    "    print(\"---individual_estimators recall-----\")\n",
    "    proba_train = pd.DataFrame()\n",
    "    proba_test = pd.DataFrame()\n",
    "    # Set the available scoring metrics\n",
    "    scoring = 'recall'\n",
    "\n",
    "    # Train a final model on the entire dataset using the same cross-validation object\n",
    "    cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1412)\n",
    "    for estimator in estimators:\n",
    "        es_name = estimator[0]\n",
    "        tic = time.time()\n",
    "        cv_results = cross_validate(estimator[1],X_train, y_train\n",
    "                             ,cv = cv\n",
    "                             ,scoring = scoring\n",
    "                             ,n_jobs = -1\n",
    "                             ,return_train_score = True\n",
    "                             ,verbose=False)\n",
    "\n",
    "        #dict_keys(['fit_time', 'score_time', 'test_score', 'train_score'])\n",
    "\n",
    "        # print the AUC scores for each fold\n",
    "        print('Mean Time cost {}s'.format(time.time() - tic))\n",
    "        print(cv_results.keys())\n",
    "        print(cv_results['test_score'])\n",
    "\n",
    "        # calculate the mean AUC score across all folds\n",
    "        mean_es = cv_results['test_score'].mean()\n",
    "        model = estimator[1].fit(X_train,y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        print('Test Time cost {}s'.format(time.time() - tic))\n",
    "        # calculate the AUC score on the test set\n",
    "        # train_auc = roc_auc_score(y_train, train_proba)\n",
    "        test_recall = recall_score(y_test, y_pred, average='macro')\n",
    "        # print(\"test AUC:\", test_auc)\n",
    "        print(estimator[0]\n",
    "          ,\"\\n Mean AUC:{}\".format(mean_es)\n",
    "          # ,\"\\n train AUC:{}\".format(train_auc)\n",
    "          ,\"\\n test AUC:{}\".format(test_recall)\n",
    "          ,\"\\n\")\n",
    "        \n",
    "    return proba_train, proba_test\n",
    "print('---recall---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b02f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion_estimators(clf):\n",
    "    \"\"\"\n",
    "    对融合模型做交叉验证，对融合模型的表现进行评估\n",
    "    \"\"\"\n",
    "    tic = time.time()\n",
    "    scoring = {'auc': 'roc_auc'}\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "    cv_results = cross_validate(clf,X_train,y_train\n",
    "                             ,cv = cv\n",
    "                             ,scoring = scoring\n",
    "                             ,n_jobs = -1\n",
    "                             ,verbose=True)\n",
    "\n",
    "    # print the AUC scores for each fold\n",
    "    print('Mean Time cost {}s'.format(time.time() - tic))\n",
    "    print(cv_results['test_auc'])\n",
    "\n",
    "    # calculate the mean AUC score across all folds\n",
    "    mean_auc = cv_results['test_auc'].mean()\n",
    "    print(\"-------------new----------------\")\n",
    "\n",
    "    clf_model = clf.fit(X_train,y_train)\n",
    "    \n",
    "    train_proba = clf_model.predict_proba(X_train)[:, 1]\n",
    "    test_proba = clf_model.predict_proba(X_test)[:, 1]\n",
    "    print('Test Time cost {}s'.format(time.time() - tic))\n",
    "    # calculate the AUC score on the test set\n",
    "    train_auc = roc_auc_score(y_train, train_proba)\n",
    "    test_auc = roc_auc_score(y_test, test_proba)\n",
    "    print(\"fusion estimators:\"\n",
    "          ,\"\\n Mean AUC:{}\".format(mean_auc)\n",
    "          ,\"\\n Train AUC:{}\".format(train_auc)\n",
    "          ,\"\\n Test AUC:{}\".format(test_auc)\n",
    "          ,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183445d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogiR(max_iter = 500,random_state=42,n_jobs=6)\n",
    "#增加特征多样性与样本多样性\n",
    "clf2 = RFC(n_estimators= 100,max_features=\"sqrt\",max_samples=0.9, random_state=42,n_jobs=8)\n",
    "#特征多样性，稍微上调特征数量\n",
    "clf3 = GBC(n_estimators= 100,max_features=16,random_state=42) \n",
    "\n",
    "#增加算法多样性，新增决策树、KNN、贝叶斯\n",
    "clf4 = DTC(max_depth=8,random_state=42)\n",
    "clf5 = KNNC(n_neighbors=10,n_jobs=8)\n",
    "# clf6 = GaussianNB()\n",
    "\n",
    "#新增随机多样性，相同的算法更换随机数种子\n",
    "clf7 = RFC(n_estimators= 100,max_features=\"sqrt\",max_samples=0.9, random_state=4869,n_jobs=8)\n",
    "clf8 = GBC(n_estimators= 100,max_features=16,random_state=4869)\n",
    "\n",
    "# Create an SVM classifier with a linear kernel\n",
    "clf9 = SVC(kernel='poly', degree=3, probability=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48ce325e",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "KNN\n",
    "SVM\n",
    "GBDT\n",
    "Decision Tree\n",
    "RandomForest\n",
    "AdaBoost\n",
    "XGBoost\n",
    "CatBoost\n",
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8978bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"Logistic Regression\",clf1), (\"RandomForest\", clf2)\n",
    "              , (\"GBDT\",clf3), (\"Decision Tree\", clf4), (\"KNN\",clf5) \n",
    "              , (\"RandomForest2\", clf7), (\"GBDT2\", clf8), (\"SVM\", clf9)\n",
    "             ]\n",
    "\n",
    "\n",
    "train_meta, test_meta = individual_estimators(estimators)\n",
    "final_estimator = RFC(n_estimators=100\n",
    "                      , min_impurity_decrease=0.0025\n",
    "                      , random_state= 420, n_jobs=6)\n",
    "final_estimator.fit(train_meta, y_train)\n",
    "test_pred = final_estimator.predict_proba(test_meta)[:,1]\n",
    "\n",
    "# message = 'Test ROC AUC:', roc_auc_score(y_test, test_pred)\n",
    "# print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimators = [  (\"Decision Tree\", clf4)\n",
    "#               , (\"RandomForest2\", clf7)\n",
    "#               , (\"GBDT2\", clf8)\n",
    "#              ]\n",
    "\n",
    "# #选择单个评估器中分数最高的随机森林作为元学习器\n",
    "# #也可以尝试其他更简单的学习器\n",
    "# final_estimator = RFC(n_estimators=100\n",
    "#                       , min_impurity_decrease=0.0025\n",
    "#                       , random_state= 420, n_jobs=6)\n",
    "# clf = StackingClassifier(estimators=estimators #level0的7个体学习器\n",
    "#                          ,final_estimator=final_estimator #level 1的元学习器\n",
    "#                          ,n_jobs=6)\n",
    "# fusion_estimators(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2381e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    XGBClassifier(learning_rate=0.5,\n",
    "                    eval_metric='auc',\n",
    "                    # n_estimators=712,  # 750\n",
    "                    n_estimators=7,  # 750\n",
    "                    max_depth=5,\n",
    "                    min_child_weight=7,\n",
    "                    gamma=0,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.6,\n",
    "                    eta=0.05,\n",
    "                    silent=1,\n",
    "                    seed=3,\n",
    "                    objective='binary:logistic',\n",
    "                    scale_pos_weight=1),\n",
    "    LGBMClassifier(num_leaves=35,\n",
    "                    learning_rate=0.5,\n",
    "                    # n_estimators=543,  # 443\n",
    "                    n_estimators=5,  # 443\n",
    "                    objective='binary',\n",
    "                    metric='auc',\n",
    "                    seed=3,\n",
    "                    colsample_bytree=0.8,\n",
    "                    min_child_weight=7,\n",
    "                    subsample=0.8,\n",
    "                    silent=1),\n",
    "    CatBoostClassifier(iterations=5,\n",
    "                        learning_rate=0.5,\n",
    "                        eval_metric='AUC',\n",
    "                        depth=8\n",
    "                        ),\n",
    "    ABC(n_estimators=50, learning_rate=1)\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d44553a",
   "metadata": {},
   "source": [
    "estimators = [(\"Logistic Regression\",clf1), (\"KNN\",clf5), (\"SVM\", clf9)\n",
    "               , (\"GBDT2\", clf8), (\"Decision Tree\", clf4), (\"RandomForest2\", clf7)\n",
    "              , (\"AdaBoost\", base_models[3]),(\"XGBClassifier\",base_models[0])\n",
    "             ]\n",
    "\n",
    "train_meta, test_meta = individual_estimators(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7345bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"Logistic Regression\",clf1), (\"KNN\",clf5)\n",
    "               , (\"GBDT2\", clf8), (\"Decision Tree\", clf4), (\"RandomForest2\", clf7)\n",
    "              , (\"AdaBoost\", base_models[3]),(\"XGBClassifier\",base_models[0]), (\"CatBoostClassifier\",base_models[2])\n",
    "              , (\"LGBMClassifier\",base_models[1])\n",
    "             ]\n",
    "\n",
    "train_meta, test_meta = individual_estimators_recall(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0dfd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimators = [(\"Logistic Regression\",clf1), (\"KNN\",clf5), (\"SVM\", clf9)\n",
    "#                , (\"GBDT2\", clf8), (\"Decision Tree\", clf4), (\"RandomForest2\", clf7)\n",
    "#               , (\"AdaBoost\", base_models[3]),(\"XGBClassifier\",base_models[0]), (\"CatBoostClassifier\",base_models[2])\n",
    "#               , (\"LGBMClassifier\",base_models[1])\n",
    "#              ]\n",
    "\n",
    "estimators = [ (\"Logistic Regression\",clf1)  \n",
    "              ,(\"Decision Tree\", clf4)\n",
    "              , (\"RandomForest2\", clf7)\n",
    "            , (\"XGBClassifier\",base_models[0])\n",
    "            , (\"LGBMClassifier\",base_models[1])\n",
    "             ]\n",
    "\n",
    "train_meta, test_meta = individual_estimators(estimators)\n",
    "final_estimator = RFC(n_estimators=100\n",
    "                      , min_impurity_decrease=0.0025\n",
    "                      , random_state= 420, n_jobs=6)\n",
    "final_estimator.fit(train_meta, y_train)\n",
    "test_pred = final_estimator.predict_proba(test_meta)[:,1]\n",
    "\n",
    "message = 'Test ROC AUC:', roc_auc_score(y_test, test_pred)\n",
    "print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta, test_meta = individual_estimators_f1(estimators)\n",
    "final_estimator = RFC(n_estimators=100\n",
    "                      , min_impurity_decrease=0.0025\n",
    "                      , random_state= 420, n_jobs=6)\n",
    "final_estimator.fit(train_meta, y_train)\n",
    "test_pred = final_estimator.predict(test_meta)\n",
    "\n",
    "message = 'Test F1:', f1_score(y_test, test_pred)\n",
    "print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30364ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"XGBClassifier\",base_models[0])\n",
    "              ,(\"LGBMClassifier\",base_models[1])\n",
    "              , (\"Decision Tree\", clf4)\n",
    "              , (\"RandomForest2\", clf7)\n",
    "              , (\"GBDT2\", clf8)\n",
    "             ]\n",
    "\n",
    "#选择单个评估器中分数最高的随机森林作为元学习器\n",
    "#也可以尝试其他更简单的学习器\n",
    "final_estimator = RFC(n_estimators=100\n",
    "                      , min_impurity_decrease=0.0025\n",
    "                      , random_state= 420, n_jobs=-1)\n",
    "clf = StackingClassifier(estimators=estimators #level0的7个体学习器\n",
    "                         ,final_estimator=final_estimator #level 1的元学习器\n",
    "                         ,n_jobs=-1)\n",
    "fusion_estimators(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1280284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "label_file = \"data/0403_churn_2.csv\"\n",
    "# create a DataFrame from the dictionary\n",
    "data = pd.read_csv(label_file, delimiter=\"\\t\", names=[\"user_id\",\"cid\",\"device_type\",\"fix_month\",\"gender\",\"current_role\",\"last_lat\",\"last_lon\",\"hometown\",\"profession\",\"source_channel\",\"work_city_id\",\"home_city_id\",\"work_lon\",\"home_lat\",\"work_lat\",\"home_lon\",\"age_section\",\"age\",\"version\",\"model\",\"label\"]).drop(\"cid\", axis=1)\n",
    "\n",
    "# one-hot encode the categorical features\n",
    "cat_features = ['hometown', 'profession', 'source_channel', 'age_section', 'version', 'model']\n",
    "df = pd.get_dummies(data, columns=cat_features)\n",
    "\n",
    "# set the column data types\n",
    "dtype = {\n",
    "    'user_id': 'int64',\n",
    "    'device_type': 'int8',\n",
    "    'fix_month': 'int8',\n",
    "    'gender': 'int8',\n",
    "    'current_role': 'int8',\n",
    "    'last_lat': 'float32',\n",
    "    'last_lon': 'float32',\n",
    "    'work_city_id': 'int32',\n",
    "    'home_city_id': 'int32',\n",
    "    'work_lon': 'float32',\n",
    "    'home_lat': 'float32',\n",
    "    'work_lat': 'float32',\n",
    "    'home_lon': 'float32',\n",
    "    'age': 'int8',\n",
    "    'label': 'int8'\n",
    "}\n",
    "\n",
    "# apply the column data types to the DataFrame\n",
    "df = df.astype(dtype)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "X_train = train_df.drop('label', axis=1)\n",
    "y_train = train_df['label']\n",
    "X_test = test_df.drop('label', axis=1)\n",
    "y_test = test_df['label']\n",
    "data_message = 'X_train.shape={}, X_test.shape={}'.format(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a087be",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = \"data/0403_churn_2.csv\"\n",
    "data = pd.read_csv(label_file, delimiter=\"\\t\", names=[\"user_id\",\"cid\",\"device_type\",\"fix_month\",\"gender\",\"current_role\",\"last_lat\",\"last_lon\",\"hometown\",\"profession\",\"source_channel\",\"work_city_id\",\"home_city_id\",\"work_lon\",\"home_lat\",\"work_lat\",\"home_lon\",\"age_section\",\"age\",\"version\",\"model\",\"label\"]).drop(\"cid\", axis=1)\n",
    "\n",
    "# set the column data types\n",
    "dtype = {\n",
    "    'user_id': 'int64',\n",
    "    'device_type': 'int8',\n",
    "    'fix_month': 'int8',\n",
    "    'gender': 'int8',\n",
    "    'current_role': 'int8',\n",
    "    'last_lat': 'float32',\n",
    "    'last_lon': 'float32',\n",
    "    'hometown': 'category',\n",
    "    'profession': 'category',\n",
    "    'source_channel': 'category',\n",
    "    'work_city_id': 'int8',\n",
    "    'home_city_id': 'int8',\n",
    "    'work_lon': 'float32',\n",
    "    'home_lat': 'float32',\n",
    "    'work_lat': 'float32',\n",
    "    'home_lon': 'float32',\n",
    "    'age_section': 'category',\n",
    "    'age': 'int8',\n",
    "    'version': 'category',\n",
    "    'model': 'category',\n",
    "    'label': 'int8'\n",
    "}\n",
    "\n",
    "# apply the column data types to the DataFrame\n",
    "df = data.astype(dtype)\n",
    "df['hometown'] = df['hometown'].cat.add_categories('NA')\n",
    "df['hometown'] = df['hometown'].fillna('NA')\n",
    "\n",
    "if type(df) == pd.DataFrame:\n",
    "    df = df.values\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776adffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "            'learning_rate': 0.05,\n",
    "            'eval_metric': 'AUC',\n",
    "            'depth': 8,\n",
    "            'logging_level': 'Info',\n",
    "            'loss_function': 'Logloss',\n",
    "            'train_dir': 'model/cgb_record/',\n",
    "            'thread_count': 6\n",
    "        }\n",
    "max_round = 1\n",
    "cv_folds = 2\n",
    "seed = 3\n",
    "save_model_path = 'model/cgb.model'\n",
    "\n",
    "dtrain = cgb.Pool(X_train, label=y_train)\n",
    "cv_result = cgb.cv(dtrain, params, num_boost_round=max_round, nfold=cv_folds, seed=seed, logging_level='Verbose')\n",
    "\n",
    "print(cv_result.keys())\n",
    "for key, value in cv_result.items():\n",
    "    print(key, value)\n",
    "\n",
    "auc_test_mean = cv_result['test-AUC-mean']\n",
    "best_round = np.argmax(auc_test_mean)\n",
    "best_auc = np.max(auc_test_mean)  # 最好的 auc 值\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stacking_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "f4558dd3f36802e4cd3159574cc0d8d7c72aecc4239a1f962b3bf9d954215d59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
